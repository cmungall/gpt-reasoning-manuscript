## Methods

### Semi-automatic generation of reasoning benchmarks from ontologies

We created a methods to generate 8 classes of benchmarks, summarized in @tbl:tasks

| code       | task                              | description                                                                |
|:-----------|:----------------------------------|:---------------------------------------------------------------------------|
| sat        | OntologyCoherencyTask             | A task to determine if an ontology is coherent.                            |
| indirect   | EntailedIndirectSuperClassTask    | A task to determine the indirect superclasses of a class.                  |
| superc     | EntailedTransitiveSuperClassTask  | A task to determine the all transitive superclasses of a class.            |
| expr       | EntailedSubClassOfExpressionTask  | A task to determine the subclasses of a class expression.                  |
| dir-sup    | EntailedDirectSuperClassTask      | A task to determine the direct superclasses of a class.                    |
| mrca       | MostRecentCommonSubsumerTask      | A task to determine the most specific common ancestors.                    |
| abox       | ABoxTask                          | A task to infer assertions over property chains and transitvity in aboxes. |
| tc         | TaxonConstraintTask               | A task to infer validity of a term for a particular taxon.                 |

Table: Different ontology tasks
{#tbl:tasks}

These are designed to test the kinds of reasoning abilities that are relevant for common knowledge-based
inference tasks. For example, the `mrca` tasks tests the ability to find commonalities using an ontology,
as used in semantic similarity algorithms underpinning phenotype-based variant prioritization. The `abox`
task is useful for link prediction over instance data, the `tc` task tests the ability to check the validity
of predicted gene functional associations, and the `expr` task reflects the ability to perform the kind
of transitive reasoning underpinning gene set enrichment.

For each task, we randomly generate 20 tasks using a fragment of either the Gene Ontology (GO) or the
Family History Knowledge Base (FHK) ontology.

### GPT-based reasoning agent

We created a GPT-based reasoning agent that is intended to perform ontological reason using
a few-shot learning approach, using instruction prompting and in-context examples.

The structure of the prompts used in the agent is as follows:

{% raw %}
```
I will provide an ontology as a list of axioms using OWL syntax. I will then ask a question about the ontology.
Answer the question, after performing reasoning over the ontology.
If there are multiple answers, list them all each on a separate line starting with the minus symbol ("-"), like a markdown list.
Here are some examples:

{{ examples }}
--

Here is the actual ontology

{{ ontology }}

Query:

{{ question }}
{{ task_specific_prompt }}    
```
{% endraw %}

Examples are task specific and can be parameterized by the means in which the LLM
is expected to "show its working". For example, the `expr` task includes examples
such as the following:

{% raw %}
```jinja

- P type TransitiveProperty
- E2 SubClassOf P some E
- E SubClassOf B
- B SubClassOf P some A
- C SubClassOf A
- D SubClassOf Q some B


QUERY: 
What are the entailed subclasses of the expression PartOf Some P?
Include indirect (transitive) descendants.
        
ANSWERS:
- B [  B SubClassOf P some A ; ]
- E [  E SubClassOf B ;  B SubClassOf P some A ; ]
- E2 [  B SubClassOf P some A ;  E SubClassOf B ;  E2 SubClassOf P some E ; ]
```
{% endraw %}

The actual ontology is provided with by using controlled natural language
descriptions of Description Logic axioms. Opaque ontology identifiers are translated
to CamelCase labels, or, optionally, to labels obfuscated via base64 encoding of the
labels.

An example task ontology is:

```yaml
- OrganelleEnvelope SubClassOf PartOf Some IntracellularOrganelle
- CellCortex SubClassOf Cytoplasm
- CellCortexRegion SubClassOf PartOf Some CellCortex
- CellCortexRegion SubClassOf CellCortex
- CellCortexRegion SubClassOf CytoplasmicRegion
- NuclearMembrane SubClassOf PartOf Some Nucleus
- NuclearMembrane SubClassOf PartOf Some NuclearEnvelope
- IntracellularMembraneBoundedOrganelle SubClassOf PartOf Some IntracellularAnatomicalStructure
- IntracellularMembraneBoundedOrganelle SubClassOf IntracellularOrganelle
- Vacuole SubClassOf PartOf Some Cytoplasm
- Vacuole SubClassOf IntracellularMembraneBoundedOrganelle
- IntracellularOrganelle SubClassOf PartOf Some IntracellularAnatomicalStructure
- NuclearEnvelope SubClassOf PartOf Some Nucleus
- NuclearEnvelope SubClassOf OrganelleEnvelope
- Nucleus SubClassOf IntracellularMembraneBoundedOrganelle
- CytoplasmicRegion SubClassOf PartOf Some Cytoplasm
- CytoplasmicRegion SubClassOf Cytoplasm
- Cytoplasm SubClassOf PartOf Some IntracellularAnatomicalStructure
```

Finally, the question is generated according to a task-specific template.

For the `expr` template is:

{% raw %}
`What are the entailed subclasses of the expression {{ predicate }} Some {{ filler }}?`
{% endraw %}

For example:

{% raw %}
`What are the entailed subclasses of the expression PartOf Some IntracellularAnatomicalStructure?`
{% endraw %}

### Chain of thought methods

Chain of thought prompts have been demonstrated to improve LLM reasoning abilities.

We explore 3 alternate methods for exploring the effect of chain of thought:

1. no explanations solicited
2. post-hoc explanation-based
3. chain-of-thought reasoning

For the first, no explanations are requested or shown in the examples.

For the second, the OWL axioms are included after each answer

For the third, natural language descriptions of the reasoning steps are shown prior to each answer.

### Models

We used both gpt-3.5-turbo and gpt-4 models (TODO: Falcon). We interfaced the GPT models via
the OpenAI API.

### Scoring

We calculated standard precision, recall, and accuracy metrics for each execution. We only evaluate the
core answer, and do not attempt to evaluate the explanations. All tasks yield a list of answers, although
some tasks only yield a single valid/invalid answer, so precision/recall on these tasks are individually
zero or one.

### Implementation

The reasoning agent is implemented as part of the OntoGPT system.

Interfacing with ontologies is done via the Ontology Access Kit (OAK) Library.
