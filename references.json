[
  {
    "type": "article",
    "id": "ngEOG0MW",
    "categories": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Yu",
        "given": "Weihao"
      },
      {
        "family": "Jiang",
        "given": "Zihang"
      },
      {
        "family": "Dong",
        "given": "Yanfei"
      },
      {
        "family": "Feng",
        "given": "Jiashi"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "abstract": "Recent powerful pre-trained language models have achieved remarkable performance on most of the popular datasets for reading comprehension. It is time to introduce more challenging datasets to push the development of this field towards more comprehensive reasoning of text. In this paper, we introduce a new Reading Comprehension dataset requiring logical reasoning (ReClor) extracted from standardized graduate admission examinations. As earlier studies suggest, human-annotated datasets usually contain biases, which are often exploited by models to achieve high accuracy without truly understanding the text. In order to comprehensively evaluate the logical reasoning ability of models on ReClor, we propose to identify biased data points and separate them into EASY set while the rest as HARD set. Empirical results show that state-of-the-art models have an outstanding ability to capture biases contained in the dataset with high accuracy on EASY set. However, they struggle on HARD set with poor performance near that of random guess, indicating more research is needed to essentially enhance the logical reasoning ability of current models.",
    "DOI": "10.48550/arxiv.2002.04326",
    "publisher": "arXiv",
    "title": "ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning",
    "URL": "https://doi.org/gr9cn4",
    "version": "3",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2002.04326"
  },
  {
    "type": "article",
    "id": "rtNEROOT",
    "categories": [
      "Computation and Language (cs.CL)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Brown",
        "given": "Tom B."
      },
      {
        "family": "Mann",
        "given": "Benjamin"
      },
      {
        "family": "Ryder",
        "given": "Nick"
      },
      {
        "family": "Subbiah",
        "given": "Melanie"
      },
      {
        "family": "Kaplan",
        "given": "Jared"
      },
      {
        "family": "Dhariwal",
        "given": "Prafulla"
      },
      {
        "family": "Neelakantan",
        "given": "Arvind"
      },
      {
        "family": "Shyam",
        "given": "Pranav"
      },
      {
        "family": "Sastry",
        "given": "Girish"
      },
      {
        "family": "Askell",
        "given": "Amanda"
      },
      {
        "family": "Agarwal",
        "given": "Sandhini"
      },
      {
        "family": "Herbert-Voss",
        "given": "Ariel"
      },
      {
        "family": "Krueger",
        "given": "Gretchen"
      },
      {
        "family": "Henighan",
        "given": "Tom"
      },
      {
        "family": "Child",
        "given": "Rewon"
      },
      {
        "family": "Ramesh",
        "given": "Aditya"
      },
      {
        "family": "Ziegler",
        "given": "Daniel M."
      },
      {
        "family": "Wu",
        "given": "Jeffrey"
      },
      {
        "family": "Winter",
        "given": "Clemens"
      },
      {
        "family": "Hesse",
        "given": "Christopher"
      },
      {
        "family": "Chen",
        "given": "Mark"
      },
      {
        "family": "Sigler",
        "given": "Eric"
      },
      {
        "family": "Litwin",
        "given": "Mateusz"
      },
      {
        "family": "Gray",
        "given": "Scott"
      },
      {
        "family": "Chess",
        "given": "Benjamin"
      },
      {
        "family": "Clark",
        "given": "Jack"
      },
      {
        "family": "Berner",
        "given": "Christopher"
      },
      {
        "family": "McCandlish",
        "given": "Sam"
      },
      {
        "family": "Radford",
        "given": "Alec"
      },
      {
        "family": "Sutskever",
        "given": "Ilya"
      },
      {
        "family": "Amodei",
        "given": "Dario"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "abstract": "Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we find that GPT-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of GPT-3 in general.",
    "DOI": "10.48550/arxiv.2005.14165",
    "publisher": "arXiv",
    "title": "Language Models are Few-Shot Learners",
    "URL": "https://doi.org/gpmv43",
    "version": "4",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2005.14165"
  },
  {
    "type": "article",
    "id": "I9fAgwdv",
    "categories": [
      "Computation and Language (cs.CL)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Liu",
        "given": "Jian"
      },
      {
        "family": "Cui",
        "given": "Leyang"
      },
      {
        "family": "Liu",
        "given": "Hanmeng"
      },
      {
        "family": "Huang",
        "given": "Dandan"
      },
      {
        "family": "Wang",
        "given": "Yile"
      },
      {
        "family": "Zhang",
        "given": "Yue"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "abstract": "Machine reading is a fundamental task for testing the capability of natural language understanding, which is closely related to human cognition in many aspects. With the rising of deep learning techniques, algorithmic models rival human performances on simple QA, and thus increasingly challenging machine reading datasets have been proposed. Though various challenges such as evidence integration and commonsense knowledge have been integrated, one of the fundamental capabilities in human reading, namely logical reasoning, is not fully investigated. We build a comprehensive dataset, named LogiQA, which is sourced from expert-written questions for testing human Logical reasoning. It consists of 8,678 QA instances, covering multiple types of deductive reasoning. Results show that state-of-the-art neural models perform by far worse than human ceiling. Our dataset can also serve as a benchmark for reinvestigating logical AI under the deep learning NLP setting. The dataset is freely available at https://github.com/lgw863/LogiQA-dataset",
    "DOI": "10.48550/arxiv.2007.08124",
    "publisher": "arXiv",
    "title": "LogiQA: A Challenge Dataset for Machine Reading Comprehension with Logical Reasoning",
    "URL": "https://doi.org/gr9cn5",
    "version": "1",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2007.08124"
  },
  {
    "type": "article",
    "id": "18cJovLK7",
    "categories": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Liu",
        "given": "Hanmeng"
      },
      {
        "family": "Ning",
        "given": "Ruoxi"
      },
      {
        "family": "Teng",
        "given": "Zhiyang"
      },
      {
        "family": "Liu",
        "given": "Jian"
      },
      {
        "family": "Zhou",
        "given": "Qiji"
      },
      {
        "family": "Zhang",
        "given": "Yue"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "abstract": "Harnessing logical reasoning ability is a comprehensive natural language understanding endeavor. With the release of Generative Pretrained Transformer 4 (GPT-4), highlighted as \"advanced\" at reasoning tasks, we are eager to learn the GPT-4 performance on various logical reasoning tasks. This report analyses multiple logical reasoning datasets, with popular benchmarks like LogiQA and ReClor, and newly-released datasets like AR-LSAT. We test the multi-choice reading comprehension and natural language inference tasks with benchmarks requiring logical reasoning. We further construct a logical reasoning out-of-distribution dataset to investigate the robustness of ChatGPT and GPT-4. We also make a performance comparison between ChatGPT and GPT-4. Experiment results show that ChatGPT performs significantly better than the RoBERTa fine-tuning method on most logical reasoning benchmarks. With early access to the GPT-4 API we are able to conduct intense experiments on the GPT-4 model. The results show GPT-4 yields even higher performance on most logical reasoning datasets. Among benchmarks, ChatGPT and GPT-4 do relatively well on well-known datasets like LogiQA and ReClor. However, the performance drops significantly when handling newly released and out-of-distribution datasets. Logical reasoning remains challenging for ChatGPT and GPT-4, especially on out-of-distribution and natural language inference datasets. We release the prompt-style logical reasoning datasets as a benchmark suite and name it LogiEval.",
    "DOI": "10.48550/arxiv.2304.03439",
    "publisher": "arXiv",
    "title": "Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4",
    "URL": "https://doi.org/gr9cn6",
    "version": "3",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2304.03439"
  }
]
